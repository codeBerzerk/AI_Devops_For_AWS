# üìù –î–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è —ñ–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü—ñ—ó K8s LLM Admin

## üéØ –ü–æ—Ç–æ—á–Ω–∏–π —Å—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç—É

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å—Ç–≤–æ—Ä–µ–Ω–∞ ‚úÖ**  
**–©–æ —Ç—Ä–µ–±–∞ –∑—Ä–æ–±–∏—Ç–∏:** –ó–∞–ø–æ–≤–Ω–∏—Ç–∏ —Ñ–∞–π–ª–∏ —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—é

---

## üìÅ –§–∞–π–ª–∏ —â–æ –≤–∂–µ –ì–û–¢–û–í–Ü (–Ω–µ —Ç—Ä–µ–±–∞ –º—ñ–Ω—è—Ç–∏)

‚úÖ **k8s_prompt_engineering.py** - –ë–∞–∑–æ–≤—ñ –ø—Ä–æ–º–ø—Ç–∏ (–∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—é)  
‚úÖ **multilang_prompts.py** - –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–º–ø—Ç—ñ–≤  
‚úÖ **eks_integration.py** - AWS EKS wrapper  

---

## üîß –§–∞–π–ª–∏ —â–æ –¢–†–ï–ë–ê –î–û–ü–ò–°–ê–¢–ò

### 1Ô∏è‚É£ **`config/settings.py`** - –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è

**–©–æ —î –∑–∞—Ä–∞–∑:** –ü–æ—Ä–æ–∂–Ω—ñ–π —Ñ–∞–π–ª  
**–©–æ –¥–æ–¥–∞—Ç–∏:** –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è —á–µ—Ä–µ–∑ Pydantic

```python
# config/settings.py

from pydantic import BaseSettings, Field
from pathlib import Path
from typing import Optional


class Settings(BaseSettings):
    """–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø—Ä–æ–µ–∫—Ç—É"""
    
    # Project
    PROJECT_NAME: str = "K8s LLM Admin"
    VERSION: str = "0.1.0"
    DEBUG: bool = Field(default=False, env="DEBUG")
    
    # Ollama LLM
    OLLAMA_BASE_URL: str = Field(default="http://localhost:11434", env="OLLAMA_URL")
    OLLAMA_MODEL: str = Field(default="llama3.2:3b-instruct", env="OLLAMA_MODEL")
    OLLAMA_TIMEOUT: int = Field(default=120, env="OLLAMA_TIMEOUT")
    
    # LLM Parameters
    LLM_TEMPERATURE: float = Field(default=0.7, env="LLM_TEMPERATURE")
    LLM_MAX_TOKENS: int = Field(default=2000, env="LLM_MAX_TOKENS")
    
    # AWS EKS
    AWS_REGION: str = Field(default="eu-west-1", env="AWS_REGION")
    AWS_PROFILE: Optional[str] = Field(default=None, env="AWS_PROFILE")
    EKS_CLUSTER_NAME: str = Field(default="", env="EKS_CLUSTER_NAME")
    
    # Kubernetes
    KUBECONFIG_PATH: Optional[str] = Field(default=None, env="KUBECONFIG")
    DEFAULT_NAMESPACE: str = Field(default="default", env="K8S_NAMESPACE")
    
    # Language
    DEFAULT_LANGUAGE: str = Field(default="uk", env="DEFAULT_LANGUAGE")
    
    # API
    API_HOST: str = Field(default="0.0.0.0", env="API_HOST")
    API_PORT: int = Field(default=8000, env="API_PORT")
    CORS_ORIGINS: list = Field(default=["*"], env="CORS_ORIGINS")
    
    # Security
    API_KEY: Optional[str] = Field(default=None, env="API_KEY")
    RATE_LIMIT: int = Field(default=30, env="RATE_LIMIT")
    
    # Logging
    LOG_LEVEL: str = Field(default="INFO", env="LOG_LEVEL")
    LOG_DIR: Path = Field(default=Path("./logs"), env="LOG_DIR")
    
    class Config:
        env_file = ".env"
        case_sensitive = True


settings = Settings()

# –°—Ç–≤–æ—Ä–∏—Ç–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
settings.LOG_DIR.mkdir(parents=True, exist_ok=True)
```

**–ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç:** üî• –í–ò–°–û–ö–ò–ô (–ø–æ—Ç—Ä—ñ–±–µ–Ω –¥–ª—è –≤—Å—å–æ–≥–æ —ñ–Ω—à–æ–≥–æ)

---

### 2Ô∏è‚É£ **`utils/logger.py`** - –õ–æ–≥—É–≤–∞–Ω–Ω—è

**–©–æ —î:** –ü–æ—Ä–æ–∂–Ω—ñ–π `__init__.py`  
**–©–æ –¥–æ–¥–∞—Ç–∏:** –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è loguru

```python
# utils/logger.py

import sys
from loguru import logger
from config.settings import settings

# –í–∏–¥–∞–ª–∏—Ç–∏ default handler
logger.remove()

# Console handler (–∑ –∫–æ–ª—å–æ—Ä–∞–º–∏)
logger.add(
    sys.stdout,
    level=settings.LOG_LEVEL,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    colorize=True
)

# File handler (–≤—Å—ñ –ª–æ–≥–∏)
if settings.LOG_DIR:
    logger.add(
        settings.LOG_DIR / "app.log",
        level="DEBUG",
        rotation="10 MB",
        retention="7 days",
        compression="zip",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}"
    )
    
    # Error logs –æ–∫—Ä–µ–º–æ
    logger.add(
        settings.LOG_DIR / "errors.log",
        level="ERROR",
        rotation="5 MB",
        retention="14 days",
        compression="zip"
    )

# Export
__all__ = ["logger"]
```

**–ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç:** üî• –í–ò–°–û–ö–ò–ô

---

### 3Ô∏è‚É£ **`llm/ollama_client.py`** - LLM Client

**–°—Ç–∞—Ç—É—Å:** –í–∂–µ —Å—Ç–≤–æ—Ä–µ–Ω–∏–π –≤ artifacts  
**–©–æ –∑—Ä–æ–±–∏—Ç–∏:** –°–∫–æ–ø—ñ—é–≤–∞—Ç–∏ –∑ artifact "K8s LLM Admin - –ü–æ–≤–Ω–∏–π –ü–ª–∞–Ω –ü—Ä–æ–µ–∫—Ç—É", —Ä–æ–∑–¥—ñ–ª "llm/ollama_client.py"

**–î–æ–¥–∞—Ç–∏ —Ç–∞–∫–æ–∂:**

```python
# llm/ollama_client.py (–≤ –∫—ñ–Ω–µ—Ü—å —Ñ–∞–π–ª—É)

# Singleton instance
_ollama_client = None

def get_ollama_client() -> OllamaClient:
    """Get global Ollama client instance"""
    global _ollama_client
    
    if _ollama_client is None:
        from config.settings import settings
        _ollama_client = OllamaClient(
            base_url=settings.OLLAMA_BASE_URL,
            model=settings.OLLAMA_MODEL,
            timeout=settings.OLLAMA_TIMEOUT
        )
    
    return _ollama_client
```

**–ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç:** üî• –ö–†–ò–¢–ò–ß–ù–ò–ô

---

### 4Ô∏è‚É£ **`llm/prompt_manager.py`** - Orchestration –ø—Ä–æ–º–ø—Ç—ñ–≤

**–©–æ —î:** –ü–æ—Ä–æ–∂–Ω—ñ–π —Ñ–∞–π–ª  
**–©–æ –¥–æ–¥–∞—Ç–∏:** –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –≤—Å—ñ—Ö —Å–∏—Å—Ç–µ–º –ø—Ä–æ–º–ø—Ç—ñ–≤

```python
# llm/prompt_manager.py

from typing import Dict, Optional, Any
from dataclasses import dataclass

from prompts.multilang_prompts import (
    prompt_manager,
    Language,
    detect_language
)
from llm.ollama_client import get_ollama_client, LLMResponse
from utils.logger import logger


@dataclass
class DiagnosticRequest:
    """–ó–∞–ø–∏—Ç –Ω–∞ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫—É"""
    user_message: str
    resource_type: Optional[str] = None
    namespace: str = "default"
    kubectl_output: Optional[str] = None
    language: Optional[Language] = None
    eks_context: Optional[Dict] = None


class PromptOrchestrator:
    """–û—Ä–∫–µ—Å—Ç—Ä–∞—Ü—ñ—è –ø—Ä–æ–º–ø—Ç—ñ–≤ —Ç–∞ LLM"""
    
    def __init__(self):
        self.llm_client = get_ollama_client()
        self.prompt_manager = prompt_manager
    
    def diagnose(self, request: DiagnosticRequest) -> LLMResponse:
        """
        –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        
        Args:
            request: Diagnostic request
        
        Returns:
            LLM response –∑ –¥—ñ–∞–≥–Ω–æ–∑–æ–º
        """
        # 1. –í–∏–∑–Ω–∞—á–∏—Ç–∏ –º–æ–≤—É —è–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–∞
        language = request.language
        if not language:
            detected = detect_language(request.user_message)
            language = detected
            logger.info(f"–í–∏–∑–Ω–∞—á–µ–Ω–∞ –º–æ–≤–∞: {detected.value}")
        
        # 2. –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –ø—Ä–æ–º–ø—Ç
        full_prompt = self.prompt_manager.build_full_prompt(
            user_message=request.user_message,
            resource_type=request.resource_type,
            language=language,
            eks_context=request.eks_context
        )
        
        logger.debug(f"–ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏–π –ø—Ä–æ–º–ø—Ç (–¥–æ–≤–∂–∏–Ω–∞: {len(full_prompt)} chars)")
        
        # 3. –í—ñ–¥–ø—Ä–∞–≤–∏—Ç–∏ –¥–æ LLM
        try:
            response = self.llm_client.generate(
                prompt=full_prompt,
                temperature=0.7,
                max_tokens=2000
            )
            
            logger.info(
                f"LLM –≤—ñ–¥–ø–æ–≤—ñ–≤ –∑–∞ {response.generation_time:.2f}s, "
                f"–∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ {response.tokens_generated} —Ç–æ–∫–µ–Ω—ñ–≤"
            )
            
            return response
        
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ LLM –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó: {e}")
            raise
    
    def chat(
        self,
        messages: list,
        language: Language = Language.UKRAINIAN
    ) -> LLMResponse:
        """Multi-turn conversation"""
        
        # –î–æ–¥–∞—Ç–∏ system prompt
        system_prompt = self.prompt_manager.get_system_prompt(
            language=language,
            include_cloud=True
        )
        
        messages_with_system = [
            {"role": "system", "content": system_prompt}
        ] + messages
        
        return self.llm_client.chat(messages_with_system)


# Global instance
orchestrator = PromptOrchestrator()
```

**–ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç:** üî• –ö–†–ò–¢–ò–ß–ù–ò–ô

---

### 5Ô∏è‚É£ **`k8s/kubectl_wrapper.py`** - Generic kubectl wrapper

**–©–æ –¥–æ–¥–∞—Ç–∏:**

```python
# k8s/kubectl_wrapper.py

import subprocess
import json
from typing import Dict, List, Optional, Any
from utils.logger import logger


class KubectlWrapper:
    """Generic kubectl wrapper (–Ω–µ EKS-—Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–∏–π)"""
    
    def __init__(self, kubeconfig: Optional[str] = None):
        self.kubeconfig = kubeconfig
    
    def _build_command(self, command: List[str]) -> List[str]:
        """Build kubectl command with kubeconfig"""
        cmd = ["kubectl"]
        
        if self.kubeconfig:
            cmd.extend(["--kubeconfig", self.kubeconfig])
        
        cmd.extend(command)
        return cmd
    
    def run(
        self,
        command: List[str],
        namespace: Optional[str] = None,
        output_format: str = "json"
    ) -> Dict[str, Any]:
        """
        Execute kubectl command
        
        Args:
            command: kubectl args (without 'kubectl')
            namespace: k8s namespace
            output_format: json, yaml, or wide
        
        Returns:
            Result dict
        """
        full_cmd = self._build_command(command)
        
        if namespace:
            full_cmd.extend(["-n", namespace])
        
        if output_format and output_format in ["json", "yaml"]:
            full_cmd.extend(["-o", output_format])
        
        try:
            logger.debug(f"–í–∏–∫–æ–Ω–∞–Ω–Ω—è: {' '.join(full_cmd)}")
            
            result = subprocess.run(
                full_cmd,
                capture_output=True,
                text=True,
                timeout=60
            )
            
            return {
                "success": result.returncode == 0,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "returncode": result.returncode,
                "command": ' '.join(full_cmd)
            }
        
        except subprocess.TimeoutExpired:
            logger.error(f"Kubectl timeout: {' '.join(full_cmd)}")
            return {
                "success": False,
                "error": "Command timeout",
                "command": ' '.join(full_cmd)
            }
        
        except Exception as e:
            logger.error(f"Kubectl error: {e}")
            return {
                "success": False,
                "error": str(e),
                "command": ' '.join(full_cmd)
            }
    
    def get(
        self,
        resource: str,
        name: Optional[str] = None,
        namespace: Optional[str] = None,
        label_selector: Optional[str] = None
    ) -> Dict:
        """kubectl get"""
        cmd = ["get", resource]
        
        if name:
            cmd.append(name)
        
        if label_selector:
            cmd.extend(["-l", label_selector])
        
        result = self.run(cmd, namespace=namespace, output_format="json")
        
        if result["success"]:
            try:
                return json.loads(result["stdout"])
            except:
                return {}
        
        return {}
    
    def describe(
        self,
        resource: str,
        name: str,
        namespace: Optional[str] = None
    ) -> str:
        """kubectl describe"""
        cmd = ["describe", resource, name]
        result = self.run(cmd, namespace=namespace, output_format=None)
        return result.get("stdout", "")
    
    def logs(
        self,
        pod_name: str,
        namespace: Optional[str] = None,
        container: Optional[str] = None,
        previous: bool = False,
        tail: int = 100
    ) -> str:
        """kubectl logs"""
        cmd = ["logs", pod_name, f"--tail={tail}"]
        
        if container:
            cmd.extend(["-c", container])
        
        if previous:
            cmd.append("--previous")
        
        result = self.run(cmd, namespace=namespace, output_format=None)
        return result.get("stdout", "")
    
    def exec(
        self,
        pod_name: str,
        command: List[str],
        namespace: Optional[str] = None,
        container: Optional[str] = None
    ) -> str:
        """kubectl exec"""
        cmd = ["exec", pod_name, "--"]
        
        if container:
            cmd.extend(["-c", container])
        
        cmd.extend(command)
        
        result = self.run(cmd, namespace=namespace, output_format=None)
        return result.get("stdout", "")


# Global instance
kubectl = KubectlWrapper()
```

**–ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç:** üü° –°–ï–†–ï–î–ù–Ü–ô

---

### 6Ô∏è‚É£ **`api/main.py`** - FastAPI app

**–©–æ –¥–æ–¥–∞—Ç–∏:**

```python
# api/main.py

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager

from config.settings import settings
from utils.logger import logger
from api.routes import diagnose, health


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup and shutdown events"""
    # Startup
    logger.info(f"üöÄ Starting {settings.PROJECT_NAME} v{settings.VERSION}")
    logger.info(f"Ollama URL: {settings.OLLAMA_BASE_URL}")
    logger.info(f"EKS Cluster: {settings.EKS_CLUSTER_NAME}")
    
    # Check Ollama health
    from llm.ollama_client import get_ollama_client
    client = get_ollama_client()
    
    if not client.health_check():
        logger.warning("‚ö†Ô∏è Ollama –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∏–π! –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —á–∏ –∑–∞–ø—É—â–µ–Ω–∏–π: ollama serve")
    else:
        logger.info("‚úÖ Ollama –ø—ñ–¥–∫–ª—é—á–µ–Ω–∏–π")
    
    yield
    
    # Shutdown
    logger.info("üëã Shutting down")


# Create app
app = FastAPI(
    title=settings.PROJECT_NAME,
    version=settings.VERSION,
    lifespan=lifespan
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(health.router, prefix="/api", tags=["health"])
app.include_router(diagnose.router, prefix="/api", tags=["diagnose"])


@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "service": settings.PROJECT_NAME,
        "version": settings.VERSION,
        "status": "running",
        "docs": "/docs"
    }


if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "api.main:app",
        host=settings.API_HOST,
        port=settings.API_PORT,
        reload=settings.DEBUG,
        log_level=settings.LOG_LEVEL.lower()
    )
```

**–ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç:** üî• –í–ò–°–û–ö–ò–ô

---

### 7Ô∏è‚É£ **`api/routes/health.py`** - Health check endpoint

```python
# api/routes/health.py

from fastapi import APIRouter
from llm.ollama_client import get_ollama_client
from config.settings import settings

router = APIRouter()


@router.get("/health")
async def health_check():
    """Health check endpoint"""
    
    # Check Ollama
    ollama_client = get_ollama_client()
    ollama_status = "healthy" if ollama_client.health_check() else "unhealthy"
    
    # Check kubectl access (optional)
    kubectl_status = "unknown"
    try:
        from k8s.kubectl_wrapper import kubectl
        result = kubectl.run(["version", "--client"])
        kubectl_status = "healthy" if result["success"] else "unhealthy"
    except:
        pass
    
    return {
        "status": "healthy",
        "version": settings.VERSION,
        "components": {
            "ollama": ollama_status,
            "kubectl": kubectl_status
        },
        "config": {
            "model": settings.OLLAMA_MODEL,
            "eks_cluster": settings.EKS_CLUSTER_NAME,
            "language": settings.DEFAULT_LANGUAGE
        }
    }
```

**–ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç:** üü¢ –ù–ò–ó–¨–ö–ò–ô (–∞–ª–µ –∫–æ—Ä–∏—Å–Ω–æ –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É)

---

### 8Ô∏è‚É£ **`api/routes/diagnose.py`** - –ì–æ–ª–æ–≤–Ω–∏–π endpoint –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏

```python
# api/routes/diagnose.py

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Optional

from llm.prompt_manager import orchestrator, DiagnosticRequest
from prompts.multilang_prompts import Language
from utils.logger import logger

router = APIRouter()


class DiagnoseRequest(BaseModel):
    """Request schema –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    message: str
    resource_type: Optional[str] = None
    namespace: str = "default"
    kubectl_output: Optional[str] = None
    language: Optional[str] = "uk"


class DiagnoseResponse(BaseModel):
    """Response schema"""
    diagnosis: str
    model: str
    generation_time: float
    tokens_generated: int


@router.post("/diagnose", response_model=DiagnoseResponse)
async def diagnose_issue(request: DiagnoseRequest):
    """
    –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ Kubernetes –ø—Ä–æ–±–ª–µ–º–∏
    
    **–ü—Ä–∏–∫–ª–∞–¥ –∑–∞–ø–∏—Ç—É:**
    ```json
    {
      "message": "–ú—ñ–π –ø–æ–¥ –≤ CrashLoopBackOff, —â–æ —Ä–æ–±–∏—Ç–∏?",
      "resource_type": "pod",
      "namespace": "production"
    }
    ```
    """
    try:
        logger.info(f"–û—Ç—Ä–∏–º–∞–Ω–æ –∑–∞–ø–∏—Ç –Ω–∞ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫—É: {request.message[:50]}...")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ language string ‚Üí enum
        lang = Language.UKRAINIAN if request.language == "uk" else Language.ENGLISH
        
        # –°—Ç–≤–æ—Ä–∏—Ç–∏ diagnostic request
        diag_req = DiagnosticRequest(
            user_message=request.message,
            resource_type=request.resource_type,
            namespace=request.namespace,
            kubectl_output=request.kubectl_output,
            language=lang,
            eks_context={
                "cluster_name": "prod-cluster",  # TODO: from settings
                "region": "eu-west-1",
                "k8s_version": "1.28"
            }
        )
        
        # –í–∏–∫–æ–Ω–∞—Ç–∏ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫—É
        response = orchestrator.diagnose(diag_req)
        
        return DiagnoseResponse(
            diagnosis=response.text,
            model=response.model,
            generation_time=response.generation_time,
            tokens_generated=response.tokens_generated
        )
    
    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/diagnose/stream")
async def diagnose_stream(request: DiagnoseRequest):
    """Streaming –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ (SSE)"""
    # TODO: Implement streaming
    raise HTTPException(status_code=501, detail="Streaming not implemented yet")
```

**–ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç:** üî• –ö–†–ò–¢–ò–ß–ù–ò–ô

---

### 9Ô∏è‚É£ **`api/models/request.py`** & **`response.py`** - Pydantic schemas

```python
# api/models/request.py

from pydantic import BaseModel, Field
from typing import Optional


class DiagnoseRequest(BaseModel):
    """–ó–∞–ø–∏—Ç –Ω–∞ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫—É"""
    message: str = Field(..., description="–û–ø–∏—Å –ø—Ä–æ–±–ª–µ–º–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é")
    resource_type: Optional[str] = Field(None, description="–¢–∏–ø —Ä–µ—Å—É—Ä—Å—É (pod, service, node)")
    namespace: str = Field(default="default", description="Kubernetes namespace")
    kubectl_output: Optional[str] = Field(None, description="–í–∏–≤—ñ–¥ kubectl –∫–æ–º–∞–Ω–¥")
    language: str = Field(default="uk", description="–ú–æ–≤–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ (uk –∞–±–æ en)")
    
    class Config:
        schema_extra = {
            "example": {
                "message": "–ú—ñ–π –ø–æ–¥ –≤ CrashLoopBackOff, —â–æ —Ä–æ–±–∏—Ç–∏?",
                "resource_type": "pod",
                "namespace": "production"
            }
        }
```

```python
# api/models/response.py

from pydantic import BaseModel
from typing import Optional, Dict, Any


class DiagnoseResponse(BaseModel):
    """–í—ñ–¥–ø–æ–≤—ñ–¥—å –∑ –¥—ñ–∞–≥–Ω–æ–∑–æ–º"""
    diagnosis: str
    model: str
    generation_time: float
    tokens_generated: int
    cached: bool = False
    
    class Config:
        schema_extra = {
            "example": {
                "diagnosis": "## 1. –®–≤–∏–¥–∫–µ —Ä–µ–∑—é–º–µ\n–ü–æ–¥ –∫—Ä–∞—à–∏—Ç—å—Å—è —á–µ—Ä–µ–∑...",
                "model": "llama3.2:3b-instruct",
                "generation_time": 12.5,
                "tokens_generated": 450,
                "cached": False
            }
        }
```

**–ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç:** üü° –°–ï–†–ï–î–ù–Ü–ô

---

## üß™ –¢–ï–°–¢–ò

### 10Ô∏è‚É£ **`tests/test_prompts.py`**

```python
# tests/test_prompts.py

import pytest
from prompts.multilang_prompts import (
    prompt_manager,
    Language,
    detect_language
)


def test_detect_ukrainian_language():
    """–¢–µ—Å—Ç –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏"""
    text = "–ú—ñ–π –ø–æ–¥ –Ω–µ –∑–∞–ø—É—Å–∫–∞—î—Ç—å—Å—è"
    lang = detect_language(text)
    assert lang == Language.UKRAINIAN


def test_detect_english_language():
    """–¢–µ—Å—Ç –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—ó"""
    text = "My pod is not starting"
    lang = detect_language(text)
    assert lang == Language.ENGLISH


def test_build_prompt_ukrainian():
    """–¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞"""
    prompt = prompt_manager.build_full_prompt(
        user_message="–¢–µ—Å—Ç–æ–≤–µ –ø–∏—Ç–∞–Ω–Ω—è",
        resource_type="pod",
        language=Language.UKRAINIAN
    )
    
    assert "–¢–∏ –µ–∫—Å–ø–µ—Ä—Ç–Ω–∏–π SRE" in prompt
    assert "Pod-Specific" in prompt


def test_get_system_prompt():
    """–¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–≥–æ system prompt"""
    prompt = prompt_manager.get_system_prompt(
        language=Language.UKRAINIAN,
        include_cloud=True
    )
    
    assert "AWS EKS" in prompt
    assert len(prompt) > 1000
```

**–ó–∞–ø—É—Å–∫:** `pytest tests/test_prompts.py`

---

### 11Ô∏è‚É£ **`tests/test_llm.py`**

```python
# tests/test_llm.py

import pytest
from llm.ollama_client import get_ollama_client


@pytest.fixture
def ollama_client():
    return get_ollama_client()


def test_ollama_health(ollama_client):
    """–¢–µ—Å—Ç –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ Ollama"""
    assert ollama_client.health_check() == True


def test_llm_generation(ollama_client):
    """–¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó"""
    response = ollama_client.generate(
        prompt="What is Kubernetes?",
        max_tokens=50
    )
    
    assert response.text
    assert len(response.text) > 10
    assert response.tokens_generated > 0


def test_list_models(ollama_client):
    """–¢–µ—Å—Ç —Å–ø–∏—Å–∫—É –º–æ–¥–µ–ª–µ–π"""
    models = ollama_client.list_models()
    assert isinstance(models, list)
    assert len(models) > 0
```

**–ó–∞–ø—É—Å–∫:** `pytest tests/test_llm.py` (–ø–æ—Ç—Ä–µ–±—É—î –∑–∞–ø—É—â–µ–Ω–∏–π Ollama)

---

## üìä –ü–†–Ü–û–†–ò–¢–ï–¢–ò –Ü–ú–ü–õ–ï–ú–ï–ù–¢–ê–¶–Ü–á

### –§–∞–∑–∞ 1: –ë–∞–∑–æ–≤–∏–π —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª (1-2 –¥–Ω—ñ) üî•
1. ‚úÖ `config/settings.py` - –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è
2. ‚úÖ `utils/logger.py` - –ª–æ–≥—É–≤–∞–Ω–Ω—è
3. ‚úÖ `llm/ollama_client.py` - LLM client
4. ‚úÖ `llm/prompt_manager.py` - orchestration
5. ‚úÖ –°–∫–æ–ø—ñ—é–≤–∞—Ç–∏ –≥–æ—Ç–æ–≤—ñ —Ñ–∞–π–ª–∏ –∑ artifacts

### –§–∞–∑–∞ 2: API (1 –¥–µ–Ω—å) üü°
6. ‚úÖ `api/main.py` - FastAPI app
7. ‚úÖ `api/routes/diagnose.py` - –≥–æ–ª–æ–≤–Ω–∏–π endpoint
8. ‚úÖ `api/routes/health.py` - health check
9. ‚úÖ `api/models/` - Pydantic schemas

### –§–∞–∑–∞ 3: K8s Integration (1-2 –¥–Ω—ñ) üü¢
10. ‚úÖ `k8s/kubectl_wrapper.py` - generic kubectl
11. ‚úÖ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∑ —Ä–µ–∞–ª—å–Ω–∏–º EKS –∫–ª–∞—Å—Ç–µ—Ä–æ–º
12. ‚úÖ –ï–º—É–ª—è—Ü—ñ—è –ø—Ä–æ–±–ª–µ–º

### –§–∞–∑–∞ 4: –¢–µ—Å—Ç–∏ (1 –¥–µ–Ω—å) üîµ
13. ‚úÖ `tests/test_prompts.py`
14. ‚úÖ `tests/test_llm.py`
15. ‚úÖ `tests/test_api.py`

---

## üöÄ –®–í–ò–î–ö–ò–ô –°–¢–ê–†–¢ (–ù–∞—Å—Ç—É–ø–Ω—ñ –∫—Ä–æ–∫–∏)

### 1. –ó–∞–ø–æ–≤–Ω–∏—Ç–∏ –∫—Ä–∏—Ç–∏—á–Ω—ñ —Ñ–∞–π–ª–∏:

```bash
# 1. Settings
nano config/settings.py
# –°–∫–æ–ø—ñ—é–≤–∞—Ç–∏ –∫–æ–¥ –∑ —Ü—å–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞

# 2. Logger
nano utils/logger.py

# 3. Ollama Client
nano llm/ollama_client.py

# 4. Prompt Manager
nano llm/prompt_manager.py

# 5. FastAPI Main
nano api/main.py

# 6. Diagnose route
nano api/routes/diagnose.py
```

### 2. –û–Ω–æ–≤–∏—Ç–∏ requirements.txt:

```txt
# –î–æ–¥–∞—Ç–∏ —è–∫—â–æ –Ω–µ–º–∞—î:
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
loguru==0.7.2
```

### 3. –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –Ω–∞ Jetson:

```bash
cd ~/k8s-llm-admin
source venv/bin/activate
pip install -r requirements.txt
```

### 4. –°—Ç–≤–æ—Ä–∏—Ç–∏ .env:

```bash
cat > .env << 'EOF'
# LLM
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b-instruct

# AWS
AWS_REGION=eu-west-1
EKS_CLUSTER_NAME=your-cluster-name

# Language
DEFAULT_LANGUAGE=uk

# API
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=true
LOG_LEVEL=INFO
EOF
```

### 5. –ó–∞–ø—É—Å—Ç–∏—Ç–∏ API:

```bash
# –¢–µ—Ä–º—ñ–Ω–∞–ª 1: Ollama
ollama serve

# –¢–µ—Ä–º—ñ–Ω–∞–ª 2: API
python api/main.py
```

### 6. –¢–µ—Å—Ç:

```bash
curl -X POST http://localhost:8000/api/diagnose \
  -H "Content-Type: application/json" \
  -d '{
    "message": "–ú—ñ–π –ø–æ–¥ –≤ CrashLoopBackOff, —â–æ —Ä–æ–±–∏—Ç–∏?",
    "resource_type": "pod",
    "namespace": "default"
  }'
```

---

## ‚úÖ Checklist –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –ö—Ä–æ–∫—É 1

```
[ ] config/settings.py –∑–∞–ø–æ–≤–Ω–µ–Ω–∏–π
[ ] utils/logger.py –ø—Ä–∞—Ü—é—î
[ ] llm/ollama_client.py –≥–æ—Ç–æ–≤–∏–π
[ ] llm/prompt_manager.py —Ä–µ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π
[ ] api/main.py —Å—Ç–≤–æ—Ä–µ–Ω–∏–π
[ ] api/routes/diagnose.py –ø—Ä–∞—Ü—é—î
[ ] api/routes/health.py –≥–æ—Ç–æ–≤–∏–π
[ ] .env —Ñ–∞–π–ª –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–∏–π
[ ] Ollama –∑–∞–ø—É—â–µ–Ω–∏–π –Ω–∞ Jetson
[ ] API —Å—Ç–∞—Ä—Ç—É—î –±–µ–∑ –ø–æ–º–∏–ª–æ–∫
[ ] Health check –ø–æ–≤–µ—Ä—Ç–∞—î 200
[ ] –¢–µ—Å—Ç–æ–≤–∏–π –∑–∞–ø–∏—Ç –ø—Ä–∞—Ü—é—î
[ ] –í—ñ–¥–ø–æ–≤—ñ–¥—å —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é
[ ] –õ–æ–≥–∏ –∑–∞–ø–∏—Å—É—é—Ç—å—Å—è
```

---

**–ü—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –ö—Ä–æ–∫—É 1** –ø–µ—Ä–µ—Ö–æ–¥–∏–º–æ –¥–æ **–ö—Ä–æ–∫—É 2: RAG —Å–∏—Å—Ç–µ–º–∞** (–≤–µ–∫—Ç–æ—Ä–Ω–∞ –ë–î, knowledge base, retrieval)!

–ì–æ—Ç–æ–≤—ñ –ø–æ—á–∞—Ç–∏ –∑–∞–ø–æ–≤–Ω—é–≤–∞—Ç–∏ —Ñ–∞–π–ª–∏? –Ø–∫–∏–π —Ñ–∞–π–ª –ø–æ—á–Ω–µ–º–æ –ø–µ—Ä—à–∏–º?